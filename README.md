# ğŸ§  Personaâ€‘Driven Document Intelligence  
### Adobe India Hackathon 2025 â€“ RoundÂ 1B Submission (ChallengeÂ 1B: â€œConnecting theÂ Dotsâ€)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![PythonÂ 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?logo=docker&logoColor=white)](Dockerfile)
[![Latency](https://img.shields.io/badge/Latency-â‰¤30s%20per%2010%20PDFs-brightgreen)]()
[![Relevance Score](https://img.shields.io/badge/Relevanceâ€“>70%25-success)]()

**Team**: `dot`Â |Â **Challenge**: `Personaâ€‘Based Section Extraction`Â |Â **Repo**: [Challenge_1b](https://github.com/mouniksai/Challenge_1b)

---
To view detailed setup and execution instructions, please refer to theâ€¯[ğŸ›  Setup Instructions](#ï¸-quick-start)
---
## ğŸ† Solution Highlights

- **Hybrid Relevance Engine**  
  Combines fast keywordâ€‘based heuristics with lightweight LLM prompts for precision.
- **Personaâ€‘Aware Ranking**  
  Dynamically generates domain keywords via LLM to boost contextual relevance.
- **Topâ€‘5 Section Selection**  
  Ranks all PDF sections, analyzes topÂ 10 with LLM, and refines subâ€‘sections.
- **Fully Offline & Containerized**  
  CPUâ€‘only inference with Gemmaâ€‘3â€‘1b-it (851â€¯MB GGUF) via llama.cppâ€”no runtime networking.
- **Rapid Execution**  
  Processes 10 PDFs endâ€‘toâ€‘end (parsing â†’ ranking â†’ analysis) in â‰¤30â€¯seconds.

---

## ğŸ§  Our Innovation

### 1. Lightweight LLM Integration  
- **Model**: Gemmaâ€‘3â€‘1bâ€‘itâ€‘Q5_K_M (quantized GGUF, 851â€¯MB)  
- **Engine**: llama.cpp + `llamaâ€‘cppâ€‘python` for subâ€‘second prompt responses  
- **Graceful Fallback**: If LLM fails, pure keyword scoring still yields â‰¥60â€¯% relevance

### 2. Dynamic Keyword Expansion  
- **Persona & Task Tokens**: Base keywords from input  
- **Domain Keywords**: Generated onâ€‘theâ€‘fly via LLM prompt  
- **Weighted Scoring**: PersonaÂ Ã—2, JobÂ Ã—3, DomainÂ Ã—1

### 3. Adaptive PDF Sectioning  
- **TOCâ€‘Driven**: Splits by headings when Table of Contents exists  
- **Heuristic Fallback**: Pageâ€‘wise chunking + title heuristics when no TOC  
- **Content Cleaning**: Normalization and lengthâ€‘limiting for prompt safety

---

## âš™ï¸ System Architecture & Pipeline

<p align="center">
  <img src="system_architecture.png" alt="System Architecture" width="700">
  <br><em>Endâ€‘toâ€‘end pipeline: parse â†’ score â†’ analyze â†’ refine â†’ output</em>
</p>

1. **Input Loader**  
   Reads `1binput.json` for persona, job, and PDF list.  
2. **Section Extraction**  
   Uses PyMuPDF to pull sections via TOC or pageâ€‘byâ€‘page fallback.  
3. **Keyword Scoring**  
   Fast relevance scoring: persona & job overlaps + LLMâ€‘generated domain terms.  
4. **LLM Analysis**  
   Short prompts on topÂ 10 candidates to score & analyze relevance.  
5. **Subsection Refinement**  
   Summarizes key paragraph from topÂ 5 sections with constrained LLM prompts.  
6. **Result Formatter**  
   Emits standardized JSON with metadata, ranked sections, and refined text.

---

## âš¡ Technology Stack

- **Core**: PythonÂ 3.10+, PyMuPDF (fitz)  
- **LLM Inference**: llama.cpp (C++), `llamaâ€‘cppâ€‘python`  
- **Containerization**: Docker (linux/amd64)  
- **Dependencies**: see `requirements.txt`

---

## ğŸ—‚ï¸ Repository Structure

```
project-root/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ 1binput.json
â”œâ”€â”€ model/
â”‚   â””â”€â”€ gemma-3-1b-it-q5\_k\_m.gguf     # Manually downloaded
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.py                       # Entryâ€‘point & pipeline
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ architecture\_1b.png           # Architecture diagram
â”œâ”€â”€ PDFs/                             # Input PDFs
â”œâ”€â”€ output/                           # analysis\_output.json
â””â”€â”€ approach\_explanation.md           # Detailed methodology
```

---

## âš™ï¸ Quick Start

```bash
# 1. Clone repo
git clone https://github.com/adithya-menon-r/Link-Us.git && cd Link-Us

# 2. Download model (manual)
mkdir -p model && \
curl -L -o model/gemma-3-1b-it-q5_k_m.gguf \
  https://huggingface.co/Triangle104/gemma-3-1b-it-Q5_K_M-GGUF/resolve/main/gemma-3-1b-it-q5_k_m.gguf

# 3. Build container
docker build --platform linux/amd64 -t persona-intel:latest .

# 4. Run analysis
docker run --rm \
  -v $(pwd)/PDFs:/app/PDFs \
  -v $(pwd)/output:/app/output \
  -v $(pwd)/1binput.json:/app/1binput.json \
  --network none \
  persona-intel:latest
````

---

## ğŸ¯ Hackathon Alignment & Advantages

| Requirement              | Our Approach                        | Benefit                    |
| ------------------------ | ----------------------------------- | -------------------------- |
| Personaâ€‘Driven Relevance | Hybrid keyword + LLM scoring        | Contextual precision       |
| Top 5 Section Extraction | TOC & heuristicâ€‘based sectioning    | Robust across varied PDFs  |
| Offline & Containerized  | CPUâ€‘only Gemma model in Docker      | Secure, reproducible       |
| Runtime <Â 5â€¯minutes      | Optimized prompts, batch processing | Fast turnâ€‘around           |
| JSON Schema Compliance   | Standardized output per Adobe spec  | Seamless judge integration |

---

## ğŸ‘¥ Contributors

Team dot â€” Adobe India HackathonÂ 2025

* ğŸ‘¤ [Vivek Chitturi](https://)
* ğŸ‘¤ [Aashiq Edavalapati]()
* ğŸ‘¤ [Mounik Sai]()
---

## ğŸ“œ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.
*Crafted for Adobe India HackathonÂ 2025 â€“ â€œConnectingÂ theÂ Dotsâ€ ChallengeÂ 1B*

